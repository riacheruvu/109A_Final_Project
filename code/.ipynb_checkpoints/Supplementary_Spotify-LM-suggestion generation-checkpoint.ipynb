{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Summary\" data-toc-modified-id=\"Summary-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Summary</a></span></li><li><span><a href=\"#Install-required-packages\" data-toc-modified-id=\"Install-required-packages-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Install required packages</a></span></li><li><span><a href=\"#Load-parquet-files,-and-do-basic-checks\" data-toc-modified-id=\"Load-parquet-files,-and-do-basic-checks-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Load parquet files, and do basic checks</a></span></li><li><span><a href=\"#Create-word-embeddedings-using-BERT-Language-Model\" data-toc-modified-id=\"Create-word-embeddedings-using-BERT-Language-Model-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Create word embeddedings using BERT Language Model</a></span></li><li><span><a href=\"#Create-word-embeddedings-using-GPT-2-Language-Model\" data-toc-modified-id=\"Create-word-embeddedings-using-GPT-2-Language-Model-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Create word embeddedings using GPT-2 Language Model</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d7QL77-gASix"
   },
   "source": [
    "## Summary\n",
    "\n",
    "As language models such as BERT trained on Wikipedia, along with other sources, when it generates word embeddings in it's high dimensional space, it would bring out relationships that we are not able to capture using conventional techniques.\n",
    "\n",
    "We follow the following basic steps:\n",
    "\n",
    "1. Loaded the Parquet file to a Dask Data Frame. Currently processing just first partition (67503 songs)\n",
    "2. Have used a concatenation of \"Artist Name, Track Name, Album Name\" as input to the language model (BERT)\n",
    "3. Used BERT base uncased as the language model. Using transformers API from Hugging Face.\n",
    "4. Generated word embedding (768 dimensional) for each song.\n",
    "5. Used Facebook AI's Faiss (Faiss is a library for efficient similarity search and clustering of dense vectors) to get similar vectors.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "msodMzYlA-wl"
   },
   "source": [
    "## Install required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 510
    },
    "colab_type": "code",
    "id": "9vpe-REsfeAJ",
    "outputId": "312889b3-9d6e-4fa8-c45a-4b40c84a3881"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.2.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.4)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.35)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.83)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.9)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
      "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.10.32)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
      "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.2.1)\n",
      "Requirement already satisfied: botocore<1.14.0,>=1.13.32 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.13.32)\n",
      "Requirement already satisfied: python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.32->boto3->transformers) (2.6.1)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.32->boto3->transformers) (0.15.2)\n",
      "Requirement already satisfied: fastparquet in /usr/local/lib/python3.6/dist-packages (0.3.2)\n",
      "Requirement already satisfied: pandas>=0.19 in /usr/local/lib/python3.6/dist-packages (from fastparquet) (0.25.3)\n",
      "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from fastparquet) (1.17.4)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from fastparquet) (1.12.0)\n",
      "Requirement already satisfied: numba>=0.28 in /usr/local/lib/python3.6/dist-packages (from fastparquet) (0.40.1)\n",
      "Requirement already satisfied: thrift>=0.11.0 in /usr/local/lib/python3.6/dist-packages (from fastparquet) (0.13.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19->fastparquet) (2018.9)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19->fastparquet) (2.6.1)\n",
      "Requirement already satisfied: llvmlite>=0.25.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.28->fastparquet) (0.30.0)\n"
     ]
    }
   ],
   "source": [
    "# install transformers to get a convenient pytorch API interface to various \n",
    "# language models such as BERT, GPT\n",
    "!pip install transformers\n",
    "\n",
    "# install fastparquet to access the parquet files generated earlier\n",
    "!pip install fastparquet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U_fAbYxFBKVY"
   },
   "source": [
    "## Load parquet files, and do basic checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "2D04JONKnoW6",
    "outputId": "b823429c-98c6-4f9e-eb5a-61b3876af8ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# make a local copy of the parquet files generated from the spotify CSV dataset\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uTYwwmelum5v"
   },
   "outputs": [],
   "source": [
    "# copy data from google drive to local folder\n",
    "# this is a time consuming step\n",
    "# !cp -a '/content/drive/My Drive/109A/project/data/' '/content/Spotify.parquet'\n",
    "# !cp -a '/content/drive/My Drive/109A/project/Spotify_Unique_Songs/' '/content/Spotify_Unique_Songs.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "ynhl6M-CnqAC",
    "outputId": "2406cc6a-3546-47bb-b659-6cb0f2af1e08"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['artist_name', 'track_name', 'album_name', 'track_uri', 'artist_uri',\n",
       "       'album_uri'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 1,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# copy data to a dask dataframe\n",
    "from dask import dataframe as dd\n",
    "from dask.dataframe import read_csv, read_parquet, to_csv, to_parquet\n",
    "\n",
    "# path = '/content/drive/My Drive/109A/project/data/'\n",
    "# path = '/content/Spotify.parquet/'\n",
    "# ddf = dd.read_parquet(path=path, engine='fastparquet')\n",
    "# ddf.columns # print the columns to verify\n",
    "\n",
    "path = '/content/drive/My Drive/109A/project/Spotify_Unique_Songs/'\n",
    "# path = '/content/Spotify_Unique_Songs.parquet/'\n",
    "ddf = dd.read_parquet(path=path, engine='fastparquet')\n",
    "ddf.columns # print the columns to verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p3kksPeWo6Eq"
   },
   "outputs": [],
   "source": [
    "# compute top 100 artists\n",
    "res = ddf.groupby('artist_name').artist_name.count().compute()\n",
    "top100 = res.sort_values(ascending=False)[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "hSp-b2jZxBXs",
    "outputId": "5268fbf0-d487-43fa-b2ad-010aa1bf5b55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top artist in the entire dataset is Drake\n"
     ]
    }
   ],
   "source": [
    "print(\"top artist in the entire dataset is {0}\".format(top100.index[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "vcIh4lxlx5_r",
    "outputId": "af82858c-d1da-45fd-baed-8ddba2babfd8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. 1 artist Drake has 46 albums\n"
     ]
    }
   ],
   "source": [
    "top = top100.index[0] # get top artist\n",
    "ddf_top = ddf[ddf['artist_name'] == top].compute() # ddf for top artist\n",
    " # print no of albums of top artist\n",
    "print(\"No. 1 artist {0} has {1} albums\".\\\n",
    "      format(top, len(ddf_top['album_uri'].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m5WLOj0M3UWi"
   },
   "outputs": [],
   "source": [
    "# no of unique artists\n",
    "# res_pCount = ddf.groupby('artist_uri').pid.nunique().compute()\n",
    "# print(\"no of unique artists in the dataset are {0}.\".format(res_pCount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XaA6Y_Y27hke"
   },
   "outputs": [],
   "source": [
    "# we will work only on the first partition for now\n",
    "# the first parition contains 67603 entries\n",
    "# ddf0 = ddf_u.get_partition(0)\n",
    "# ddf0 = ddf.get_partition(0)\n",
    "# ddf0.describe().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5osNIBDhn1Ug"
   },
   "outputs": [],
   "source": [
    "# !cp -a ./Spotify_Unique_Songs.parquet/. './drive/My Drive/109A/project/Spotify_Unique_Songs/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lvo4ifkQT4yv"
   },
   "source": [
    "## Create word embeddedings using BERT Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "colab_type": "code",
    "id": "ERsot5DjOTPs",
    "outputId": "e93ad000-cfe6-447e-e0d4-9f40b5e7959a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tqdm import tqdm_notebook # for progress bar\n",
    "from torch.utils.data import TensorDataset, DataLoader, SequentialSampler\n",
    "import numpy as np\n",
    "from dask import dataframe as dd\n",
    "from dask.dataframe import read_csv, read_parquet, to_csv, to_parquet\n",
    "\n",
    "device = 'cuda'\n",
    "\n",
    "# Load tokenizer, model from pretrained model/vocabulary\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Models are now set in evaluation mode by default when instantiated\n",
    "# with the from_pretrained() method\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "# send model to cuda to use GPU for processing\n",
    "model.to(device);\n",
    "\n",
    "path = '/content/drive/My Drive/109A/project/Spotify_Unique_Songs/'\n",
    "# path = '/content/Spotify_Unique_Songs.parquet/'\n",
    "ddf_u = dd.read_parquet(path=path, engine='fastparquet')\n",
    "\n",
    "track_embeddings = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ffh0oM_Xy8rd"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tqdm import tqdm_notebook # for progress bar\n",
    "from torch.utils.data import TensorDataset, DataLoader, SequentialSampler\n",
    "import numpy as np\n",
    "from dask import dataframe as dd\n",
    "from dask.dataframe import read_csv, read_parquet, to_csv, to_parquet\n",
    "import datetime\n",
    "\n",
    "device = 'cuda'\n",
    "\n",
    "# Load tokenizer, model from pretrained model/vocabulary\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Models are now set in evaluation mode by default when instantiated\n",
    "# with the from_pretrained() method\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "# send model to cuda to use GPU for processing\n",
    "model.to(device);\n",
    "\n",
    "path = '/content/drive/My Drive/109A/project/Spotify_Unique_Songs/'\n",
    "# path = '/content/Spotify_Unique_Songs.parquet/'\n",
    "ddf_u = dd.read_parquet(path=path, engine='fastparquet')\n",
    "\n",
    "track_embeddings = []\n",
    "\n",
    "# same code can be used for all paritions\n",
    "# however, memory constraints prevent us from doing so\n",
    "\n",
    "# for p in range(ddf_u.npartitions):\n",
    "for p in range(1):\n",
    "  print(\"processing parition[{0}/{1}] \".format(p,ddf_u.npartitions), end=\"\")\n",
    "  ddf = ddf_u.get_partition(p)\n",
    "  # ddf.dropna()\n",
    "  song_data = ddf.compute()\n",
    "  song_data.dropna(inplace=True)\n",
    "  # track_names = song_data['track_name'].to_list()\n",
    "  \n",
    "  ######\n",
    "  # step 1: tokenize\n",
    "  ######\n",
    "  print(\"[1 \", end=\"\")\n",
    "  # step 1.1: create string of \"artist name - track name - album name\"\n",
    "  # step 1.2: enclose with [CLS] & [SEP] token, as required by BERT\n",
    "  # step 1.3: encode the text into the encoding used by BERT\n",
    "\n",
    "  # do this for all songs\n",
    "  indexed_tokens = [tokenizer.encode(\n",
    "                                    song_data.iloc[i,0] + \" - \" + \\\n",
    "                                    song_data.iloc[i,1] + \" - \" + \\\n",
    "                                    song_data.iloc[i,2],\n",
    "                                    add_special_tokens=True) \\\n",
    "                    for i in range(len(song_data))]\n",
    "   \n",
    "  ######\n",
    "  # step 2: remove false words\n",
    "  ######\n",
    "  print(\" 2 \", end=\"\")\n",
    "  # false words are words in the album names that do not have significance\n",
    "  # from perspective of song suggestions, but tends to throw BERT off\n",
    "\n",
    "  falseWords = 'Deluxe Edition Remastered'\n",
    "  falseWords_tokens = tokenizer.encode(falseWords)\n",
    "\n",
    "  for song in indexed_tokens:\n",
    "    for falseWord in falseWords_tokens:\n",
    "      while falseWord in song:\n",
    "        song.remove(falseWord)\n",
    "\n",
    "  ######\n",
    "  # step 3: padding\n",
    "  ######\n",
    "  print(\" 3 \", end=\"\")\n",
    "  # we need to pad token strings generated earlier so that each has the same length\n",
    "  MAX_LEN = 0\n",
    "  for text in indexed_tokens:\n",
    "    if len(text) > MAX_LEN:\n",
    "      MAX_LEN = len(text)\n",
    "\n",
    "  MAX_LEN += 1\n",
    "\n",
    "  indexed_tokens_p = pad_sequences(indexed_tokens, maxlen=MAX_LEN, \n",
    "                            dtype =\"long\", truncating=\"post\",padding =\"post\")\n",
    "\n",
    "  # Convert inputs to PyTorch tensors\n",
    "  tokens_tensors = torch.tensor(indexed_tokens_p)\n",
    "\n",
    "  ######\n",
    "  # step 4: prepare dataset and dataloader\n",
    "  ######\n",
    "  print(\" 4 \", end=\"\")\n",
    "  batch_size = 1024\n",
    "  tds = TensorDataset(tokens_tensors)\n",
    "  ss = SequentialSampler(tds)\n",
    "  dataloader = DataLoader(tds, sampler=ss, batch_size=batch_size)\n",
    "\n",
    "  ######\n",
    "  # step 5: generate word embeddings\n",
    "  ######\n",
    "  # print(\" 5 \", end = \"\")\n",
    "  print(\" 5 ]\")\n",
    "  for tokens_tensor in tqdm_notebook(dataloader):\n",
    "    tokens_tensor_cuda = tokens_tensor[0].to('cuda')\n",
    "    with torch.no_grad():\n",
    "      outputs = model(tokens_tensor_cuda)\n",
    "    del tokens_tensor_cuda\n",
    "\n",
    "    # The last hidden-state is the first element of the output tuple\n",
    "\n",
    "    track_embedding = torch.mean(outputs[0], 1).to('cpu')\n",
    "    del outputs\n",
    "    track_embedding = [t.tolist() for t in track_embedding]\n",
    "    track_embeddings.extend(track_embedding)\n",
    "  \n",
    "  # track_details.extend(song_data['track_uri', 'track_name', 'artist_name', 'album_name'].to_list())\n",
    "  # print(\" 6 ]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "skWQRshyDqkX"
   },
   "outputs": [],
   "source": [
    "# save results in a numpy array on a google drive location\n",
    "\n",
    "######\n",
    "# step 6: create numpy array\n",
    "######\n",
    "\n",
    "del track_vectors\n",
    "track_vectors = np.column_stack((song_data, track_embeddings))\n",
    "np.save('/content/drive/My Drive/109A/project/data/track_vectors-part00', \\\n",
    "        track_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "HhFlNfy1Wbjz",
    "outputId": "d5190253-c8cc-4138-87aa-730a689bbc16"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tue Dec 10 10:38:30 2019       ',\n",
       " '+-----------------------------------------------------------------------------+',\n",
       " '| NVIDIA-SMI 440.36       Driver Version: 418.67       CUDA Version: 10.1     |',\n",
       " '|-------------------------------+----------------------+----------------------+',\n",
       " '| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |',\n",
       " '| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |',\n",
       " '|===============================+======================+======================|',\n",
       " '|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |',\n",
       " '| N/A   74C    P0    86W / 149W |      0MiB / 11441MiB |      0%      Default |',\n",
       " '+-------------------------------+----------------------+----------------------+',\n",
       " '                                                                               ',\n",
       " '+-----------------------------------------------------------------------------+',\n",
       " '| Processes:                                                       GPU Memory |',\n",
       " '|  GPU       PID   Type   Process name                             Usage      |',\n",
       " '|=============================================================================|',\n",
       " '|  No running processes found                                                 |',\n",
       " '+-----------------------------------------------------------------------------+']"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MVmkRtQMUEH-"
   },
   "source": [
    "## Create word embeddedings using GPT-2 Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 100,
     "referenced_widgets": [
      "903b0b848bc74ed5ae9f4461e04d95a1",
      "93c77a0678654d65aefa403f36fb740a",
      "49342a914e1c4258af9375e67bbc0a9a",
      "2b5a228142b24fceb312a2fc278bfe2b",
      "d5859f91fc754ebbb44016e4090a29de",
      "de4de274773d4254b1c3aefe4735ee0c",
      "2974162015124e248465e359db5fed51",
      "cd06263898f5451891ad219325647d04"
     ]
    },
    "colab_type": "code",
    "id": "-qw5eX7iUHLC",
    "outputId": "9165b76b-082b-4a76-c972-d24894227a65"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing parition[0/20] [1  2  3  4  5 ]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "903b0b848bc74ed5ae9f4461e04d95a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=221), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# from transformers import BertTokenizer, BertModel\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tqdm import tqdm_notebook # for progress bar\n",
    "from torch.utils.data import TensorDataset, DataLoader, SequentialSampler\n",
    "import numpy as np\n",
    "from dask import dataframe as dd\n",
    "from dask.dataframe import read_csv, read_parquet, to_csv, to_parquet\n",
    "import datetime\n",
    "\n",
    "from transformers import GPT2Tokenizer, GPT2Model\n",
    "\n",
    "# Load tokenizer, model from pretrained model/vocabulary\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = GPT2Model.from_pretrained('gpt2')\n",
    "model.to('cuda');\n",
    "\n",
    "device = 'cuda'\n",
    "\n",
    "path = '/content/drive/My Drive/109A/project/Spotify_Unique_Songs/'\n",
    "# path = '/content/Spotify_Unique_Songs.parquet/'\n",
    "ddf_u = dd.read_parquet(path=path, engine='fastparquet')\n",
    "\n",
    "track_embeddings = []\n",
    "\n",
    "# same code can be used for all paritions\n",
    "# however, memory constraints prevent us from doing so\n",
    "\n",
    "# for p in range(ddf_u.npartitions):\n",
    "for p in range(1):\n",
    "  print(\"processing parition[{0}/{1}] \".format(p,ddf_u.npartitions), end=\"\")\n",
    "  ddf = ddf_u.get_partition(p)\n",
    "  # ddf.dropna()\n",
    "  song_data = ddf.compute()\n",
    "  song_data.dropna(inplace=True)\n",
    "  # track_names = song_data['track_name'].to_list()\n",
    "  \n",
    "  ######\n",
    "  # step 1: tokenize\n",
    "  ######\n",
    "  print(\"[1 \", end=\"\")\n",
    "  # step 1.1: create string of \"artist name - track name - album name\"\n",
    "  # step 1.2: enclose with [CLS] & [SEP] token, as required by BERT\n",
    "  # step 1.3: encode the text into the encoding used by BERT\n",
    "\n",
    "  # do this for all songs\n",
    "  indexed_tokens = [tokenizer.encode(\n",
    "                                    song_data.iloc[i,0] + \" - \" + \\\n",
    "                                    song_data.iloc[i,1] + \" - \" + \\\n",
    "                                    song_data.iloc[i,2],\n",
    "                                    add_special_tokens=False) \\\n",
    "                    for i in range(len(song_data))]\n",
    "   \n",
    "  ######\n",
    "  # step 2: remove false words\n",
    "  ######\n",
    "  print(\" 2 \", end=\"\")\n",
    "  # false words are words in the album names that do not have significance\n",
    "  # from perspective of song suggestions, but tends to throw BERT off\n",
    "\n",
    "  falseWords = 'Deluxe Edition Remastered'\n",
    "  falseWords_tokens = tokenizer.encode(falseWords)\n",
    "\n",
    "  for song in indexed_tokens:\n",
    "    for falseWord in falseWords_tokens:\n",
    "      while falseWord in song:\n",
    "        song.remove(falseWord)\n",
    "\n",
    "  ######\n",
    "  # step 3: padding\n",
    "  ######\n",
    "  print(\" 3 \", end=\"\")\n",
    "  # we need to pad token strings generated earlier so that each has the same length\n",
    "  MAX_LEN = 0\n",
    "  for text in indexed_tokens:\n",
    "    if len(text) > MAX_LEN:\n",
    "      MAX_LEN = len(text)\n",
    "\n",
    "  MAX_LEN += 1\n",
    "\n",
    "  indexed_tokens_p = pad_sequences(indexed_tokens, maxlen=MAX_LEN, \n",
    "                            dtype =\"long\", truncating=\"post\",padding =\"post\")\n",
    "\n",
    "  # Convert inputs to PyTorch tensors\n",
    "  tokens_tensors = torch.tensor(indexed_tokens_p)\n",
    "\n",
    "  ######\n",
    "  # step 4: prepare dataset and dataloader\n",
    "  ######\n",
    "  print(\" 4 \", end=\"\")\n",
    "  batch_size = 512\n",
    "  tds = TensorDataset(tokens_tensors)\n",
    "  ss = SequentialSampler(tds)\n",
    "  dataloader = DataLoader(tds, sampler=ss, batch_size=batch_size)\n",
    "\n",
    "  ######\n",
    "  # step 5: generate word embeddings\n",
    "  ######\n",
    "  # print(\" 5 \", end = \"\")\n",
    "  print(\" 5 ]\")\n",
    "  for tokens_tensor in tqdm_notebook(dataloader):\n",
    "    tokens_tensor_cuda = tokens_tensor[0].to('cuda')\n",
    "    with torch.no_grad():\n",
    "      outputs = model(tokens_tensor_cuda)\n",
    "    del tokens_tensor_cuda\n",
    "\n",
    "    # The last hidden-state is the first element of the output tuple\n",
    "\n",
    "    track_embedding = torch.mean(outputs[0], 1).to('cpu')\n",
    "    del outputs\n",
    "    track_embedding = [t.tolist() for t in track_embedding]\n",
    "    track_embeddings.extend(track_embedding)\n",
    "  \n",
    "  # track_details.extend(song_data['track_uri', 'track_name', 'artist_name', 'album_name'].to_list())\n",
    "  # print(\" 6 ]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1eIQR52rVCWA"
   },
   "outputs": [],
   "source": [
    "# save results in a numpy array on a google drive location\n",
    "\n",
    "######\n",
    "# step 6: create numpy array\n",
    "######\n",
    "\n",
    "del track_vectors\n",
    "track_vectors = np.column_stack((song_data, track_embeddings))\n",
    "np.save('/content/drive/My Drive/109A/project/data/track_vectors-part00-GPT2', \\\n",
    "        track_vectors)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "SpotifyEDA.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "2974162015124e248465e359db5fed51": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2b5a228142b24fceb312a2fc278bfe2b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cd06263898f5451891ad219325647d04",
      "placeholder": "​",
      "style": "IPY_MODEL_2974162015124e248465e359db5fed51",
      "value": "100% 221/221 [25:02&lt;00:00,  6.66s/it]"
     }
    },
    "49342a914e1c4258af9375e67bbc0a9a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_de4de274773d4254b1c3aefe4735ee0c",
      "max": 221,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d5859f91fc754ebbb44016e4090a29de",
      "value": 221
     }
    },
    "903b0b848bc74ed5ae9f4461e04d95a1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_49342a914e1c4258af9375e67bbc0a9a",
       "IPY_MODEL_2b5a228142b24fceb312a2fc278bfe2b"
      ],
      "layout": "IPY_MODEL_93c77a0678654d65aefa403f36fb740a"
     }
    },
    "93c77a0678654d65aefa403f36fb740a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cd06263898f5451891ad219325647d04": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d5859f91fc754ebbb44016e4090a29de": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "de4de274773d4254b1c3aefe4735ee0c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
