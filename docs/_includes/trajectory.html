<!-- Services Section -->
    <section id="trajectory">
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading">Project Trajectory</h2>
                    <h3 class="section-subheading text-muted">The journey of how our progress molded our implementation goals.</h3>
                </div>
            </div>
            <div class="row">
                <div class="col-lg-12">
                    <ul class="timeline">
                        <li>
                            <div class="timeline-image">
                                <img class="img-circle img-responsive" src="img/about/1.jpg" alt="">
                            </div>
                            <div class="timeline-panel">
                                <div class="timeline-heading">
                                    <h4>Features</h4>
                                    <h4 class="subheading">Design choices for the dataset</h4>
                                </div>
                                <div class="timeline-body">
                                    <p class="text-muted">We initially tried to add genre as a feature included in our dataset, and retrieve these labels using Spotipy's API.
                                    We found that Spotify's API makes the process of obtaining genre labels complicated, since we needed to use the artists' genre labels, since the genre labels for a particular track/song are almost always empty. We were able to retrieve the genre labels and classify certain sub-categories of genres under umbrella categories (e.g. Classical and Soundtrack). We ran into issues when we identified numerous sub-genres that could be grouped into multiple different categories - for example, should "Pop Rock" be grouped into the Pop or Rock genre? Furthermore, the song produced by an artists may not have the same genre as the genre most associated with the artist, so we discarded this feature and chose to rely on the audio features instead as our foundation.</p>
                                </div>
                            </div>
                        </li>
                        <li class="timeline-inverted">
                            <div class="timeline-image">
                                <img class="img-circle img-responsive" src="img/about/2.jpg" alt="">
                            </div>
                            <div class="timeline-panel">
                                <div class="timeline-heading">
                                    <h4>Refining our recommender system</h4>
                                    <h4 class="subheading">Design choices for the models</h4>
                                </div>
                                <div class="timeline-body">
                                    <p class="text-muted">As mentioned in the previous section, in order to personalize and further narrow down the generated recommendations, we built upon our baseline model by utilizing the clustering approach to interpret the clusters the initial playlist were assigned to, and recommend songs accordingly. We previously experimented with a Logistic Regression and Linear regression model to predict the pos variable, or the position of the track in the playlist. Since the pos variable can be considered as both categorical and numerical, we tried using unregularized Logistic and Linear regression models, which led to sub-optimal accuracy. We chose not to pursue this approach so we could focus on the personalization of the recommendations and the overall system pipeline combining sentiment analysis + the recommender system. </p>
                                </div>
                            </div>
                        </li>
                        <li>
                            <div class="timeline-image">
                                <img class="img-circle img-responsive" src="img/about/3.jpg" alt="">
                            </div>
                            <div class="timeline-panel">
                                <div class="timeline-heading">
                                    <h4>Sentiment Analysis</h4>
                                    <h4 class="subheading">Design choices for the models</h4>
                                </div>
                                <div class="timeline-body">
                                    <p class="text-muted">We first tried usign the BERT algorithm, and later used GPT-2 due to the differences in the training dataset. TODO - Elaborate.</p>
                                    <p>BERT image source: https://www.charactour.com/hub/characters/view/Bert.Sesame-Street</p>
                                </div>
                            </div>
                        </li>
                        <li class="timeline-inverted">
                            <div class="timeline-image">
                                <img class="img-circle img-responsive" src="img/about/4.jpg" alt="">
                            </div>
                            <div class="timeline-panel">
                                <div class="timeline-heading">
                                    <h4>Metrics</h4>
                                    <h4 class="subheading">Design choices for evaluating models</h4>
                                </div>
                                <div class="timeline-body">
                                    <p class="text-muted">In order to ascertain the effectiveness of our model we have decided to determine the R-precision of our model following the guidelines of the RecSys challenge. We use cosine distance to determine which songs are related to our initial playlist, and subsequently determine based on the total number of related songs and the number we retrieve what our R-precision is. The winner of RecSys 2018 had a R-precision of .22, but was allowed only 3 features, which we initially wanted to beat.

                                    After considering this further, qe feel that the usage of the R-precision metric needs to be given much thought, due to certain issues:

                        - What is defined as a relevant track? Does this mean tracks that have a high cosine similarity - if so, what is the cut-off value?
                        - The same song can be present in multiple playlists, so we cannot expect R_precision to be calculated for a particular playlist at a time and averaged across all playlists.
                        - - Just because the songs that are recommended by the system are not in the playlist database does not mean that the user will not be open to listening to these songs if they match the user's preferences. In other words, define the "relevancy" of a track, which is not nessarily associated with "relatedness" of a track? This question is the core motivation for this project. An accurate way to validate the recommendations would be to utilize an adaptive experimental study design, such a factorial design in cases where the response variable is quantitative (e.g. number of likes) or stratified analysis in cases where the response variable is qualitiative (e.g. did the user add this track to the playlist or not?).

                        Due to time constraints, we were not able to address the further, so we moved on with the other parts of the project.

                    </p>
                                </div>
                            </div>
                        </li>
                        <li class="timeline-inverted">
                            <div class="timeline-image">
                                <h4>The
                                    <br>finalized
                                    <br>pipeline</h4>
                            </div>
                        </li>
                    </ul>
                </div>
            </div>
        </div>
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading">Results and Demo</h2>
                </div>

        <h3 class="section-subheading text-muted">One song input playlist</h3>
        Let's walk through a scenario, where the user inputs one song (an extreme case of the cold start problem to demonstrate our system is able to adjust to such an input).

        First, the user provides their preferences: <br/>
        <img src="img/input_quiz.JPG" alt="input_quiz">

        Below, we present the output of the model - we combine the recommendations of the recommender system + clustering approach + GPT-2 model recommendations to obtain the following.

        We leave ranking these recommendations further (perhaps by ranking by the values of the features) as future work.<br/>

        <img src="img/combined_recommendations.JPG" alt="combined_recommendations"><br/>

        <h3 class="section-subheading text-muted">Four song input playlist</h3>

        We can also walk through a scenario, where the user inputs multiple songs (which our recommendation system supports).

        <b>Inputted playlist: It Wasn't Me; FourFiveSeconds; Black Widow; Girl On Fire</b>
        
        <img src="img/multiple_playlist_quiz.JPG" alt="multiple_playlist_quiz">
        <img src="img/combined_recommendations_multiple.JPG" alt="combined_recommendations_multiple"><br/>


        </div>
        </div>

        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading">Interpretation</h2>
                </div>


            <b><i>We met our goal of building a human-centered system for automatic playlist generation targeted at providing an intuitive system for the cold start problem, integrating unsupervised learning, sentiment analysis, and traditional recommender system solutions.</i></b>
            <p>Our models seem to do a good job of recommending tracks with similar audio features to the initial tracks. Training our models on larger datasets might lead to more recommendations being part of the playlist database, but we also considered that users might be more open to tracks that aren't necessarily part of the dataset we use. We incorporate this into our pipeline, by letting the user override our initial hypotheses about the users' preferences, forming a <b>feedback loop</b></p>.

            <p>Our results demonstrate that musical sensabilities are challenging to determine, and are often a combination of multiple different features.

            In our clustering analysis, we only considered five features, but perhaps using more features would lead to a more personalizable playlist that matches the users' preferences.</p>

            <p>   Through the constructed UI, it is possible to deploy such a system directly for pilot testing. For example, we could utilize an adaptive experimental study design, such a factorial design in cases where the response variable is quantitative (e.g. number of likes) or stratified analysis in cases where the response variable is qualitiative (e.g. did the user add this track to the playlist or not?) in order to best identify if our recommendations match users' preferences.</p>

            <b><p>We hope the impact of this model is to contribute to the literature by emphasizing the need for user control as part of the end-to-end music recommendation pipeline, and integrating various sub-disciplines (e.g. unsupervised learnign and sentiment analysis) to come up with an efficient recommendation system.</p></b>


        </div>
        </div>
    </section>
