{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SpotifyEDA.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3p7iCciqrNEj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#\n",
        "# CREDIT: https://stackoverflow.com/a/39225039\n",
        "#\n",
        "\n",
        "import requests\n",
        "\n",
        "def progress_bar(some_iter):\n",
        "    try:\n",
        "        from tqdm import tqdm\n",
        "        return tqdm(some_iter)\n",
        "    except ModuleNotFoundError:\n",
        "        return some_iter\n",
        "\n",
        "def download_file_from_google_drive(id, destination):\n",
        "  print(\"Trying to fetch {}\".format(destination))\n",
        "\n",
        "  def get_confirm_token(response):\n",
        "    for key, value in response.cookies.items():\n",
        "      if key.startswith('download_warning'):\n",
        "        return value\n",
        "\n",
        "    return None\n",
        "\n",
        "  def save_response_content(response, destination):\n",
        "    CHUNK_SIZE = 32768\n",
        "\n",
        "    with open(destination, \"wb\") as f:\n",
        "      for chunk in progress_bar(response.iter_content(CHUNK_SIZE)):\n",
        "        if chunk: # filter out keep-alive new chunks\n",
        "          f.write(chunk)\n",
        "\n",
        "  URL = \"https://docs.google.com/uc?export=download\"\n",
        "\n",
        "  session = requests.Session()\n",
        "\n",
        "  response = session.get(URL, params = { 'id' : id }, stream = True)\n",
        "  token = get_confirm_token(response)\n",
        "\n",
        "  if token:\n",
        "    params = { 'id' : id, 'confirm' : token }\n",
        "    response = session.get(URL, params = params, stream = True)\n",
        "\n",
        "  save_response_content(response, destination)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYX1L5hurV6H",
        "colab_type": "code",
        "outputId": "73d0a510-dce9-4ac0-a4f5-43e20521276e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# download from public google drive link\n",
        "# https://drive.google.com/open?id=1ofOXCLTpJAjfK07RuqputX-xx_11xsuz\n",
        "download_file_from_google_drive(\"1ofOXCLTpJAjfK07RuqputX-xx_11xsuz\", \\\n",
        "                                \"./Spotify.zip\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trying to fetch ./Spotify.zip\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "149661it [02:04, 1201.46it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IN6DpMf53sWk",
        "colab_type": "code",
        "outputId": "8f4ef1e0-3fa0-40c9-f035-5fe0ddd767f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# unzip file. for some issue with the original zip file, \n",
        "# python zipfile in unable to process the file\n",
        "\n",
        "!unzip -o -q Spotify.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "warning [Spotify.zip]:  4294967296 extra bytes at beginning or within zipfile\n",
            "  (attempting to process anyway)\n",
            "file #1:  bad zipfile offset (local header sig):  4294967296\n",
            "  (attempting to re-compensate)\n",
            "file #882:  bad zipfile offset (local header sig):  868912\n",
            "  (attempting to re-compensate)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24S-Rh6ttRxu",
        "colab_type": "code",
        "outputId": "cd082656-680b-4b0d-f570-fd12dad2bc4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# lets extract one csv file and explore its header\n",
        "import pandas as pd\n",
        "\n",
        "songsDF = pd.read_csv(\"./Songs/songs1.csv\")\n",
        "\n",
        "songsDF.columns"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['pid', 'pos', 'artist_name', 'track_uri', 'artist_uri', 'track_name',\n",
              "       'album_uri', 'duration_ms', 'album_name'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fi-r2e7eeqf",
        "colab_type": "code",
        "outputId": "25c498b8-91d5-41f4-deb5-611c616027bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "# install fastparquet\n",
        "# parquet is column based database that can handle a huge\n",
        "# amount of data, even if it does not fit in memmory\n",
        "!pip install fastparquet"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting fastparquet\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/58/49/dccb790fa17ab3fbf84a6b848050083c7a1899e9586000e34e3e4fbf5538/fastparquet-0.3.2.tar.gz (151kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 3.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.19 in /usr/local/lib/python3.6/dist-packages (from fastparquet) (0.25.2)\n",
            "Requirement already satisfied: numba>=0.28 in /usr/local/lib/python3.6/dist-packages (from fastparquet) (0.40.1)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from fastparquet) (1.17.3)\n",
            "Collecting thrift>=0.11.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c6/b4/510617906f8e0c5660e7d96fbc5585113f83ad547a3989b80297ac72a74c/thrift-0.11.0.tar.gz (52kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 7.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from fastparquet) (1.12.0)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19->fastparquet) (2.6.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19->fastparquet) (2018.9)\n",
            "Requirement already satisfied: llvmlite>=0.25.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.28->fastparquet) (0.30.0)\n",
            "Building wheels for collected packages: fastparquet, thrift\n",
            "  Building wheel for fastparquet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fastparquet: filename=fastparquet-0.3.2-cp36-cp36m-linux_x86_64.whl size=253216 sha256=99d254d0a8a11a64ca75f1df0ca500e6b0fa5ea76c9b45de109b899dcb4056b3\n",
            "  Stored in directory: /root/.cache/pip/wheels/b9/36/13/01416a760ddcab0eb8281ec9c9ffcbed945c9b831647c8b904\n",
            "  Building wheel for thrift (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for thrift: filename=thrift-0.11.0-cp36-cp36m-linux_x86_64.whl size=326441 sha256=23cf9c93940c9e66845ef93ba131bbf5689d25a574f228332658293974b6c607\n",
            "  Stored in directory: /root/.cache/pip/wheels/be/36/81/0f93ba89a1cb7887c91937948519840a72c0ffdd57cac0ae8f\n",
            "Successfully built fastparquet thrift\n",
            "Installing collected packages: thrift, fastparquet\n",
            "Successfully installed fastparquet-0.3.2 thrift-0.11.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HAM2Fxu6cAu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "from dask import dataframe as dd\n",
        "from dask.dataframe import read_csv, read_parquet, to_csv, to_parquet\n",
        "\n",
        "# create a dask data frame of all the csv files\n",
        "ddf = read_csv(urlpath=os.path.join(\"./Songs\", '*.csv'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-zi_kCTM8iR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# write that dask dataframe parquet structure\n",
        "# using engine='fastparquet' as dask supports that engine\n",
        "ddf.to_parquet('./Spotify.parquet', engine='fastparquet')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6bKsobIgM-G",
        "colab_type": "code",
        "outputId": "215f1f8b-a346-4974-d510-5c82b82f7da2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "# mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkSj8_32jliA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# copy parquet files to google drive\n",
        "!cp -a ./Spotify.parquet/. './drive/My Drive/109A/project/data/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGNgAZTAlyo_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# basic check of parquet file\n",
        "# read into a dask dataframe\n",
        "ddfP = read_parquet('./Spotify.parquet', engine='fastparquet')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5C5y6yqxsD5w",
        "colab_type": "code",
        "outputId": "95de9a52-4092-4115-b605-6da0e3b164e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "# compute number of entries per artist\n",
        "ddfP.groupby('artist_name').artist_name.count().compute()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "artist_name\n",
              "!llmind                                         130\n",
              "\"Weird Al\" Yankovic                            4569\n",
              "$teven Cannon                                   302\n",
              "$uicideBoy$                                   13662\n",
              "'In The Heights' Original Broadway Company      614\n",
              "                                              ...  \n",
              "The Brotherhood                                   1\n",
              "Thelman Houston                                   1\n",
              "Trip                                              1\n",
              "Widelows                                          1\n",
              "xmas songs                                        1\n",
              "Name: artist_name, Length: 287739, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3x1MNtQKtwuJ",
        "colab_type": "text"
      },
      "source": [
        "# Create a Parquet file containing all unique songs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ka0L22poeMN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ddf_u = ddf[['artist_name', 'track_name', 'album_name', 'track_uri', 'artist_uri', 'album_uri']].drop_duplicates(subset='track_uri')\n",
        "ddf_u.dropna()\n",
        "ddf_u = ddf_u.repartition(npartitions=20)\n",
        "ddf_u.to_parquet('./Spotify_Unique_Songs.parquet', engine='fastparquet')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7Bv8Lx7ohaA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp -a ./Spotify_Unique_Songs.parquet/. './drive/My Drive/109A/project/Spotify_Unique_Songs/'"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}